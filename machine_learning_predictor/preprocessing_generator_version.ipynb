{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c3c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, image as mpimg\n",
    "import pandas as pd\n",
    "from difficulty_levels import DifficultyLevels\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from typing import Optional\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "download_folder = \"tracking_data_download\"\n",
    "labeled_images_folder = \"labeled_images\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "NUMBER_OF_CLASSES = 3\n",
    "\n",
    "results_folder = \"ml_results\"\n",
    "data_folder_path = os.path.join(\"..\", \"post_processing\", download_folder)\n",
    "# print(data_folder_path)\n",
    "\n",
    "NEW_IMAGE_SIZE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30f279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e6bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result_plot(train_history, epochs, metric=\"categorical_accuracy\", output_folder=results_folder,\n",
    "                     output_name=\"train_history.png\"):\n",
    "\n",
    "    acc = train_history.history[f\"{metric}\"]\n",
    "    val_acc = train_history.history[f\"val_{metric}\"]\n",
    "    loss = train_history.history[\"loss\"]\n",
    "    val_loss = train_history.history[\"val_loss\"]\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # save plot to file and show in a new window\n",
    "    plt.savefig(os.path.join(output_folder, output_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8ca732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifficultyImageClassifier:\n",
    "    \"\"\"\n",
    "    Custom CNN for predicting the difficulty level with images of a user's face.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_generator, val_generator, num_classes, num_epochs=32):\n",
    "        self.n_classes = num_classes\n",
    "        self.n_epochs = num_epochs\n",
    "\n",
    "        self.train_generator = train_generator\n",
    "        self.validation_generator = val_generator\n",
    "\n",
    "        self.step_size_train = train_generator.n // train_generator.batch_size\n",
    "        self.step_size_val = val_generator.n // val_generator.batch_size\n",
    "\n",
    "        self.model_name = \"Difficulty-CNN-Model-Generator.h5\"\n",
    "        self.model_path = os.path.join(results_folder, self.model_name)\n",
    "\n",
    "        self.checkpoint_path = os.path.join(results_folder, \"checkpoints_gen\",\n",
    "                                            \"checkpoint-improvement-{epoch:02d}-{val_categorical_accuracy:.3f}.ckpt\")\n",
    "\n",
    "    def build_model(self, input_shape: tuple[Optional[int], int, int, int]) -> tf.keras.Model:\n",
    "        self.sequential_model = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "                tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "                tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "                tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "                tf.keras.layers.Flatten(),\n",
    "                # units in the last layer should be a power of two\n",
    "                tf.keras.layers.Dense(units=1024, activation=\"relu\"),\n",
    "                tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "                # units must be the number of classes -> we want a vector that looks like this: [0.2, 0.5, 0.3]\n",
    "                tf.keras.layers.Dense(units=self.n_classes, activation=\"softmax\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.sequential_model.summary()\n",
    "        self.sequential_model.compile(optimizer=\"adam\",\n",
    "                                      loss=\"categorical_crossentropy\",\n",
    "                                      metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "        return self.sequential_model\n",
    "\n",
    "\n",
    "    def train_classifier(self):\n",
    "        num_workers = 8\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(self.checkpoint_path, monitor='val_categorical_accuracy', verbose=1, mode=\"max\",\n",
    "                                              save_best_only=True, save_weights_only=True)\n",
    "        lr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
    "\n",
    "        history = self.sequential_model.fit(self.train_generator,\n",
    "                                            steps_per_epoch=self.step_size_train,\n",
    "                                            validation_data=self.validation_generator,\n",
    "                                            validation_steps=self.step_size_val,\n",
    "                                            use_multiprocessing=False,\n",
    "                                            workers=num_workers,\n",
    "                                            epochs=self.n_epochs,\n",
    "                                            callbacks=[checkpoint_callback, lr_callback],\n",
    "                                            verbose=1)\n",
    "\n",
    "        self.sequential_model.save(self.model_path)\n",
    "\n",
    "        show_result_plot(history, self.n_epochs, metric=\"categorical_accuracy\",\n",
    "                         output_name=\"train_history_custom_generator.png\")\n",
    "\n",
    "        return history\n",
    "\n",
    "    def evaluate_classifier(self):\n",
    "        val_loss, val_acc = self.sequential_model.evaluate(self.validation_generator,\n",
    "                                                           steps=self.step_size_val,\n",
    "                                                           verbose=1)\n",
    "        print(\"Validation loss: \", val_loss)\n",
    "        print(\"Validation accuracy: \", val_acc * 100)\n",
    "\n",
    "    def predict(self, test_images):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8915d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Structure based on https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_frame, x_col_name, y_col_name, batch_size, num_classes=3,\n",
    "                 images_base_path=\".\", use_grayscale=False, shuffle=False):\n",
    "\n",
    "        self.original_df = data_frame.copy()\n",
    "        self.df = data_frame.copy()\n",
    "        self.X_col = x_col_name\n",
    "        self.y_col = y_col_name\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = num_classes\n",
    "        self.images_base_path = images_base_path\n",
    "        self.use_grayscale = use_grayscale\n",
    "        self.should_shuffle = shuffle\n",
    "\n",
    "        self.n = len(self.df)\n",
    "        self.indices = self.df.index.to_list()\n",
    "\n",
    "        num_channels = 1 if self.use_grayscale else 3\n",
    "        self.output_size = (*NEW_IMAGE_SIZE, num_channels)\n",
    "\n",
    "        # create a random order for the samples\n",
    "        self.index_order = self.generate_random_index_list()\n",
    "\n",
    "    def generate_random_index_list(self):\n",
    "        sample_indices = []\n",
    "        for i in range(0, self.n, self.batch_size):\n",
    "            sample_indices.append(i)\n",
    "\n",
    "        random.shuffle(sample_indices)\n",
    "        return sample_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.should_shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Return a new sample in the form (X, y) where X is an image and y the corresponding label.\n",
    "\n",
    "        Args:\n",
    "            index: the number of the current sample from 0 to __len__() - 1\n",
    "        \"\"\"\n",
    "        actual_index = self.index_order[index]\n",
    "\n",
    "        # Take all elements starting from the current index until the start of the next index\n",
    "        sample_rows = self.df[actual_index:actual_index + self.batch_size]\n",
    "\n",
    "        X, y = self.__get_data(sample_rows)\n",
    "        return X, y\n",
    "\n",
    "    def __get_data(self, sample):\n",
    "        # Setup arrays for the image and label data\n",
    "        X = np.empty((self.batch_size, *self.output_size))\n",
    "        y = np.empty((self.batch_size, self.n_classes))\n",
    "\n",
    "        # Load and preprocess the images and labels for the current sample\n",
    "        i = 0\n",
    "        for idx, row in sample.iterrows():\n",
    "            img_path = row[self.X_col]\n",
    "            image_path = os.path.join(self.images_base_path, img_path)\n",
    "            X[i, ] = self.__scale_and_convert_image(image_path)  # load image and resize and scale it\n",
    "\n",
    "            label = row[self.y_col]\n",
    "            y[i, ] = DifficultyLevels.get_one_hot_encoding(label)  # convert string label to one-hot-vector\n",
    "            i += 1\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __scale_and_convert_image(self, image_path):\n",
    "        try:\n",
    "            color_mode = \"grayscale\" if self.use_grayscale else \"rgb\"\n",
    "\n",
    "            image = tf.keras.preprocessing.image.load_img(image_path, color_mode=color_mode)\n",
    "            image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "            # crop or pad image depending on it's size\n",
    "            resized_img = tf.image.resize_with_crop_or_pad(image_arr,\n",
    "                                                           target_height=NEW_IMAGE_SIZE[1],\n",
    "                                                           target_width=NEW_IMAGE_SIZE[0])\n",
    "\n",
    "            # normalize pixel values to [0, 1] so the ml model can work with smaller values\n",
    "            scaled_img = resized_img.numpy() / 255.0\n",
    "            return scaled_img\n",
    "\n",
    "        except Exception as e:\n",
    "            sys.stderr.write(f\"\\nError in processing image '{image_path}': {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_image_shape(self):\n",
    "        return self.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316485c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ab686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9cf27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_participant_image_logs(participant_list):\n",
    "    image_data_frame = pd.DataFrame()\n",
    "    post_processing_folder_path = os.path.join(\"..\", \"post_processing\")\n",
    "\n",
    "    for participant in participant_list:\n",
    "        images_label_log = os.path.join(post_processing_folder_path, download_folder, participant, \"labeled_images.csv\")\n",
    "        labeled_images_df = pd.read_csv(images_label_log)\n",
    "\n",
    "        image_data_frame = pd.concat([image_data_frame, labeled_images_df])\n",
    "\n",
    "    # add the index numbers as own column (reset the index first as the concatenate above creates duplicate indexes)\n",
    "    image_data_frame_numbered = image_data_frame.reset_index(drop=True)\n",
    "    image_data_frame_numbered[\"index\"] = image_data_frame_numbered.index\n",
    "\n",
    "    return image_data_frame_numbered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0018a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(participant_list, train_ratio=0.8):\n",
    "    random.shuffle(participant_list)\n",
    "\n",
    "    train_split = int(len(participant_list) * train_ratio)\n",
    "    train_participants = participant_list[:train_split]\n",
    "    test_participants = participant_list[train_split:]\n",
    "    print(f\"{len(train_participants)} participants used for training: {train_participants}\")\n",
    "    print(f\"{len(test_participants)} participants used for validation: {test_participants}\")\n",
    "\n",
    "    return train_participants, test_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97b69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_preprocessing():\n",
    "    set_random_seed()  # set seed for reproducibility\n",
    "\n",
    "    without_participants = [\"participant_1\", \"participant_2\", \"participant_4\", \"participant_5\", \"participant_6\",\n",
    "                            \"participant_7\", \"participant_8\", \"participant_9\", \"participant_11\", \"participant_12\",\n",
    "                            \"participant_13\"]\n",
    "\n",
    "    all_participants = os.listdir(data_folder_path)\n",
    "    # remove some participants for testing\n",
    "    all_participants = [p for p in all_participants if p not in set(without_participants)]\n",
    "\n",
    "    train_participants, test_participants = split_train_test(all_participants)\n",
    "\n",
    "    train_data = merge_participant_image_logs(train_participants)\n",
    "    val_data = merge_participant_image_logs(test_participants)\n",
    "\n",
    "    train_batch_size = 32\n",
    "    val_batch_size = 32\n",
    "    print(f\"Train batch size: {train_batch_size} (Data len: {len(train_data)})\")\n",
    "    print(f\"Validation batch size: {val_batch_size} (Data len: {len(val_data)})\")\n",
    "\n",
    "    for difficulty_level in train_data.difficulty.unique():\n",
    "        difficulty_level_df = train_data[train_data.difficulty == difficulty_level]\n",
    "        print(f\"Found {len(difficulty_level_df)} train images for category \\\"{difficulty_level}\\\".\")\n",
    "\n",
    "    images_path = os.path.join(\"..\", \"post_processing\")\n",
    "    use_gray = False\n",
    "    train_generator = CustomImageDataGenerator(data_frame=train_data, x_col_name=\"image_path\", y_col_name=\"difficulty\",\n",
    "                                               batch_size=train_batch_size, images_base_path=images_path,\n",
    "                                               use_grayscale=use_gray, shuffle=False)\n",
    "\n",
    "    val_generator = CustomImageDataGenerator(data_frame=val_data, x_col_name=\"image_path\", y_col_name=\"difficulty\",\n",
    "                                             batch_size=val_batch_size, images_base_path=images_path,\n",
    "                                             use_grayscale=use_gray, shuffle=False)\n",
    "\n",
    "    image_shape = train_generator.get_image_shape()\n",
    "    number_epochs = 32\n",
    "\n",
    "    classifier = DifficultyImageClassifier(train_generator, val_generator, num_classes=NUMBER_OF_CLASSES,\n",
    "                                           num_epochs=number_epochs)\n",
    "    classifier.build_model(input_shape=image_shape)\n",
    "    classifier.train_classifier()\n",
    "    classifier.evaluate_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 participants used for training: ['participant_14', 'participant_10']\n",
      "1 participants used for validation: ['participant_3']\n",
      "Train batch size: 32 (Data len: 53056)\n",
      "Validation batch size: 32 (Data len: 20222)\n",
      "Found 17702 train images for category \"medium\".\n",
      "Found 17600 train images for category \"hard\".\n",
      "Found 17754 train images for category \"easy\".\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 25,787,459\n",
      "Trainable params: 25,787,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "1658/1658 [==============================] - 2073s 1s/step - loss: 1.2218 - categorical_accuracy: 0.3197 - val_loss: 1.0986 - val_categorical_accuracy: 0.3332\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.33315, saving model to ml_results\\checkpoints_gen\\checkpoint-improvement-01-0.333.ckpt\n",
      "Epoch 2/32\n",
      "1658/1658 [==============================] - 2361s 1s/step - loss: 1.0993 - categorical_accuracy: 0.3326 - val_loss: 1.0985 - val_categorical_accuracy: 0.3376\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.33315 to 0.33756, saving model to ml_results\\checkpoints_gen\\checkpoint-improvement-02-0.338.ckpt\n",
      "Epoch 3/32\n",
      "1658/1658 [==============================] - 2087s 1s/step - loss: 1.0993 - categorical_accuracy: 0.3136 - val_loss: 1.0987 - val_categorical_accuracy: 0.3293\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.33756\n",
      "Epoch 4/32\n",
      "1658/1658 [==============================] - 2106s 1s/step - loss: 1.1004 - categorical_accuracy: 0.3165 - val_loss: 1.0985 - val_categorical_accuracy: 0.3293\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.33756\n",
      "Epoch 5/32\n",
      "1658/1658 [==============================] - 2049s 1s/step - loss: 1.0998 - categorical_accuracy: 0.3274 - val_loss: 1.0986 - val_categorical_accuracy: 0.3332\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.33756\n",
      "Epoch 6/32\n",
      "1658/1658 [==============================] - 2016s 1s/step - loss: 1.0992 - categorical_accuracy: 0.3372 - val_loss: 1.0985 - val_categorical_accuracy: 0.3332\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.33756\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/32\n",
      "  48/1658 [..............................] - ETA: 23:06 - loss: 1.1004 - categorical_accuracy: 0.2292"
     ]
    }
   ],
   "source": [
    "start_preprocessing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
